---
sidebar: sidebar 
permalink: bp/saphana_fas_fc_storage_controller_setup.html 
keywords: storage, controller, setup, storage, efficiency volume, encryption, quality, configure, disk, connection, aggregate 
summary: 이 섹션에서는 NetApp 스토리지 시스템 구성에 대해 설명합니다. 해당 ONTAP 설치 및 구성 가이드에 따라 기본 설치 및 설정을 완료해야 합니다. 
---
= 스토리지 컨트롤러 설정
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에서는 NetApp 스토리지 시스템 구성에 대해 설명합니다. 해당 ONTAP 설치 및 구성 가이드에 따라 기본 설치 및 설정을 완료해야 합니다.



== 스토리지 효율성

SSD 구성의 SAP HANA에서는 인라인 중복제거, 볼륨 간 인라인 중복제거, 인라인 압축, 인라인 컴팩션이 지원됩니다.

HDD 구성에서 스토리지 효율성 기능을 사용하도록 설정하는 것은 지원되지 않습니다.



== NetApp FlexGroup 볼륨

SAP HANA에는 NetApp FlexGroup 볼륨 사용이 지원되지 않습니다. SAP HANA의 아키텍처로 인해 FlexGroup 볼륨을 사용할 경우 이점이 없으므로 성능 문제가 발생할 수 있습니다.



== NetApp 볼륨 및 애그리게이트 암호화

SAP HANA에서는 NVE(NetApp Volume Encryption) 및 NAE(NetApp Aggregate Encryption)를 사용할 수 있습니다.



== 서비스 품질

QoS를 사용하면 공유 컨트롤러에서 특정 SAP HANA 시스템 또는 SAP 이외의 애플리케이션에 대한 스토리지 처리량을 제한할 수 있습니다.



=== 운영 및 개발/테스트

한 가지 사용 사례는 개발 및 테스트 시스템의 처리량을 제한하여 혼합 설정에서 운영 시스템에 영향을 주지 않도록 하는 것입니다. 사이징 프로세스 중에 비운영 시스템의 성능 요구사항을 결정해야 합니다. 개발 및 테스트 시스템은 일반적으로 SAP에서 정의한 운영 시스템 KPI의 20% ~ 50% 범위에서 낮은 성능 값으로 사이징할 수 있습니다. 대규모 쓰기 I/O는 스토리지 시스템에 가장 큰 성능 영향을 미칩니다. 따라서 QoS 처리량 제한은 데이터 및 로그 볼륨에서 해당 쓰기 SAP HANA 스토리지 성능 KPI 값의 백분율로 설정해야 합니다.



=== 공유 환경

또 다른 사용 사례는 쓰기가 많은 워크로드의 처리량을 제한하는 것이며, 특히 이러한 워크로드가 지연 시간에 민감한 쓰기 워크로드에 영향을 미치지 않도록 하는 것입니다. 이러한 환경에서는 개별 스토리지 오브젝트의 최대 처리량을 지정된 값으로 제한하기 위해 비공유 처리량 상한 QoS 그룹 정책을 각 SVM(Storage Virtual Machine) 내의 각 LUN에 적용하는 것이 좋습니다. 따라서 단일 워크로드가 다른 워크로드에 부정적인 영향을 미칠 수 있는 가능성이 줄어듭니다.

이렇게 하려면 각 SVM에 대해 ONTAP 클러스터의 CLI를 사용하여 그룹 정책을 생성해야 합니다.

....
qos policy-group create -policy-group <policy-name> -vserver <vserver name> -max-throughput 1000MB/s -is-shared false
....
SVM 내의 각 LUN에 적용됩니다. 아래는 SVM 내의 모든 기존 LUN에 정책 그룹을 적용하는 예입니다.

....
lun modify -vserver <vserver name>  -path * -qos-policy-group  <policy-name>
....
이 작업은 모든 SVM에 대해 수행해야 합니다. 각 SVM의 QoS 경찰 그룹 이름은 달라야 합니다. 새 LUN의 경우 정책을 직접 적용할 수 있습니다.

....
lun create -vserver <vserver_name> -path  /vol/<volume_name>/<lun_name>   -size <size> -ostype <e.g. linux>  -qos-policy-group <policy-name>
....
지정된 LUN의 최대 처리량으로 1000MB/s를 사용하는 것이 좋습니다. 애플리케이션에 더 많은 처리량이 필요한 경우 LUN 스트라이핑이 포함된 여러 LUN을 사용하여 필요한 대역폭을 제공해야 합니다. 이 가이드는 섹션 에서 Linux LVM 기반 SAP HANA에 대한 예를 https://docs.netapp.com/us-en/netapp-solutions-sap/bp/saphana_fas_fc_host_setup.html#create-lvm-volume-groups-and-logical-volumes["호스트 설정"] 제공합니다.


NOTE: 이 제한은 읽기에도 적용됩니다. 따라서 SAP HANA 데이터베이스 시작 시간 및 백업에 필요한 SLA를 충족하기 위해 충분한 LUN을 사용하십시오.



== NetApp FabricPool를 참조하십시오

SAP HANA 시스템의 액티브 운영 파일 시스템에 NetApp FabricPool 기술을 사용하면 안 됩니다. 여기에는 데이터 및 로그 영역을 위한 파일 시스템과 '/HANA/공유' 파일 시스템이 포함됩니다. 따라서 특히 SAP HANA 시스템을 시작할 때 성능을 예측할 수 없습니다.

"스냅샷 전용" 계층화 정책을 사용하는 것은 물론 SnapVault 또는 SnapMirror 대상과 같은 백업 대상에서 FabricPool를 사용하는 것도 가능합니다.


NOTE: FabricPool를 사용하여 운영 스토리지의 스냅샷 복사본을 계층화하거나 백업 대상에서 FabricPool를 사용하면 데이터베이스의 복원 및 복구 또는 시스템 클론 생성, 복구 시스템과 같은 기타 작업에 필요한 시간이 변경됩니다. 전체 수명 주기 관리 전략을 계획할 때 이 기능을 사용하는 동안 SLA가 여전히 충족되는지 확인하십시오.

FabricPool는 로그 백업을 다른 스토리지 계층으로 이동하는 데 적합한 옵션입니다. 백업을 이동하면 SAP HANA 데이터베이스를 복구하는 데 필요한 시간이 달라집니다. 따라서 "dediing-minimum-cooling-days" 옵션을 로컬 고속 스토리지 계층에 복구를 위해 정기적으로 필요한 로그 백업을 배치하는 값으로 설정해야 합니다.



== 스토리지를 구성합니다

다음 개요에는 필요한 스토리지 구성 단계가 요약되어 있습니다. 각 단계는 다음 섹션에서 자세히 설명합니다. 이 단계를 시작하기 전에 스토리지 하드웨어 설정, ONTAP 소프트웨어 설치 및 스토리지 FCP 포트의 SAN 패브릭 연결을 완료합니다.

. 에 설명된 대로 디스크 쉘프의 구성이 올바른지 확인합니다<<디스크 쉘프 연결>>.
. 에 설명된 대로 필요한 애그리게이트를 생성하고 <<애그리게이트 구성>>구성합니다.
. 에 설명된 대로 스토리지 가상 머신(SVM)을 <<스토리지 가상 머신 구성>>생성합니다.
. 에 설명된 대로 논리 인터페이스(LIF)를 <<논리 인터페이스 구성>>생성합니다.
. 섹션 링크에 설명된 대로 HANA 서버의 WWN(Worldwide Name)으로 이니시에이터 그룹(igroup)을 생성합니다. saphana_FAS_fc_storage_controller_setup.html#initiator-groups.<<이니시에이터 그룹>>
. 및 섹션에 설명된 대로 애그리게이트 내에 볼륨 및 LUN을 생성합니다 <<SAP HANA 단일 호스트 시스템을 위한 볼륨 및 LUN 구성>><<SAP HANA 다중 호스트 시스템을 위한 볼륨 및 LUN 구성>>
. 에 설명된 대로 애그리게이트 내에 이니시에이터 그룹, 볼륨 및 LUN을 <<#lun_create,LUN 생성, 볼륨 및 LUN을 이니시에이터 그룹에 매핑>>생성합니다.




== 디스크 쉘프 연결

HDD를 사용할 경우 다음 그림과 같이 최대 2개의 DS2246 디스크 쉘프 또는 4개의 DS224C 디스크 쉘프를 하나의 SAS 스택에 연결하여 SAP HANA 호스트에 필요한 성능을 제공할 수 있습니다. 각 쉘프 내의 디스크는 HA 쌍의 두 컨트롤러에 균등하게 분산되어야 합니다.

image:saphana_fas_fc_image10.png["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]

SSD를 사용할 경우, 다음 그림과 같이 하나의 SAS 스택에 최대 하나의 디스크 쉘프를 연결하여 SAP HANA 호스트에 필요한 성능을 제공할 수 있습니다. 각 쉘프 내의 디스크는 HA 쌍의 두 컨트롤러에 균등하게 분산되어야 합니다. DS224C 디스크 쉘프를 사용하면 4중 경로 SAS 케이블도 사용할 수 있지만 필수는 아닙니다.

image:saphana_fas_fc_image11.png["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]



=== NVMe(100GbE) 디스크 쉘프

각 NS224 NVMe 디스크 쉘프는 다음 그림과 같이 컨트롤러당 2개의 100GbE 포트를 통해 연결됩니다. 각 쉘프 내의 디스크는 HA 쌍의 두 컨트롤러에 균등하게 분산되어야 합니다.

image:saphana_fas_ns224.png["MVMe 디스크 쉘프 연결"]



== 애그리게이트 구성

일반적으로 사용되는 디스크 쉘프 또는 디스크 기술(SSD 또는 HDD)에 관계없이 컨트롤러당 2개의 애그리게이트를 구성해야 합니다. 이 단계는 사용 가능한 모든 컨트롤러 리소스를 사용할 수 있도록 하는 데 필요합니다. FAS 2000 시리즈 시스템의 경우 한 개의 데이터 집합만으로도 충분합니다.



=== HDD를 포함한 애그리게이트 구성

다음 그림에서는 8개의 SAP HANA 호스트에 대한 구성을 보여 줍니다. 각 스토리지 컨트롤러에 4개의 SAP HANA 호스트가 연결되어 있습니다. 각 스토리지 컨트롤러에 하나씩, 두 개의 개별 애그리게이트가 구성됩니다. 각 애그리게이트는 4 × 10 = 40개의 데이터 디스크(HDD)로 구성됩니다.

image:saphana_fas_fc_image12.png["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]



=== SDD 전용 시스템을 사용하여 구성을 집계합니다

일반적으로 사용되는 디스크 쉘프 또는 디스크 기술(SSD 또는 HDD)과 관계없이 컨트롤러당 2개의 애그리게이트를 구성해야 합니다.

다음 그림에서는 ADPv2로 구성된 12Gb SAS 쉘프에서 실행 중인 12개의 SAP HANA 호스트 구성을 보여 줍니다. 각 스토리지 컨트롤러에 6개의 SAP HANA 호스트가 연결되어 있습니다. 각 스토리지 컨트롤러에 2개씩, 4개의 개별 애그리게이트가 구성됩니다. 각 애그리게이트에는 디스크 11개와 데이터 9개, 패리티 디스크 파티션 2개가 구성되어 있습니다. 각 컨트롤러에 대해 2개의 스페어 파티션을 사용할 수 있습니다.

image:saphana_fas_fc_image13.jpg["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]



== 스토리지 가상 머신 구성

SAP HANA 데이터베이스를 사용하는 다중 호스트 SAP 환경에는 단일 SVM이 사용될 수 있습니다. 회사 내의 서로 다른 팀에서 관리되는 경우 필요에 따라 SVM을 각 SAP 환경에 할당할 수도 있습니다. 이 문서의 스크린샷과 명령 출력에는 HANA라는 SVM이 사용됩니다.



== 논리 인터페이스 구성

스토리지 클러스터 구성 내에서 하나의 네트워크 인터페이스(LIF)를 생성하여 전용 FCP 포트에 할당해야 합니다. 예를 들어, 성능상의 이유로 FCP 포트 4개가 필요한 경우 LIF 4개를 생성해야 합니다. 다음 그림은 SVM에 구성된 8개 LIF의 스크린샷을 보여줍니다.

image:saphana_fas_fc_image14a.png["논리 인터페이스 개요"]

ONTAP 9 System Manager를 사용하여 SVM을 생성할 때 필요한 물리적 FCP 포트를 모두 선택할 수 있으며 물리적 포트당 하나의 LIF가 자동으로 생성됩니다.

다음 그림에서는 ONTAP System Manager를 사용하여 SVM 및 LIF를 생성하는 방법을 보여 줍니다.

image:saphana_fas_fc_image15a.png["SVM 생성"]



== 이니시에이터 그룹

igroup은 각 서버 또는 LUN에 대한 액세스가 필요한 서버 그룹에 대해 구성할 수 있습니다. igroup을 구성하려면 서버의 WWPN(Worldwide Port Name)이 필요합니다.

'sanlun' 툴을 사용하여 각 SAP HANA 호스트의 WWPN을 얻으려면 다음 명령을 실행합니다.

....
stlrx300s8-6:~ # sanlun fcp show adapter
/sbin/udevadm
/sbin/udevadm

host0 ...... WWPN:2100000e1e163700
host1 ...... WWPN:2100000e1e163701
....

NOTE: 'NetApp' 툴은 NetApp 호스트 유틸리티의 일부이며 각 SAP HANA 호스트에 설치해야 합니다. 자세한 내용은 섹션을 참조하십시오 link:saphana_fas_fc_host_setup.html["호스트 설정."]

이니시에이터 그룹은 ONTAP 클러스터의 CLI를 사용하여 생성할 수 있습니다.

....
lun igroup create -igroup <igroup name> -protocol fcp -ostype linux -initiator <list of initiators> -vserver <SVM name>
....


== SAP HANA 단일 호스트 시스템을 위한 볼륨 및 LUN 구성

다음 그림은 4개의 단일 호스트 SAP HANA 시스템의 볼륨 구성을 보여줍니다. 각 SAP HANA 시스템의 데이터 및 로그 볼륨은 서로 다른 스토리지 컨트롤러에 분산됩니다. 예를 들어, 볼륨이 `SID1_data_mnt00001` 컨트롤러 A에 구성되고 볼륨은 `SID1_log_mnt00001` 컨트롤러 B에 구성됩니다. 각 볼륨 내에서는 단일 LUN이 구성됩니다.


NOTE: SAP HANA 시스템에 고가용성(HA) 쌍의 스토리지 컨트롤러가 하나만 사용되는 경우 데이터 볼륨 및 로그 볼륨을 동일한 스토리지 컨트롤러에 저장할 수도 있습니다.

image:saphana_fas_fc_image18.jpg["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]

각 SAP HANA 호스트마다 데이터 볼륨, 로그 볼륨 및 '/HANA/shared'에 대한 볼륨이 구성됩니다. 다음 표에는 4개의 SAP HANA 단일 호스트 시스템이 포함된 구성의 예가 나와 있습니다.

|===
| 목적 | 컨트롤러 A의 애그리게이트 1 | 컨트롤러 A의 애그리게이트 2 | 컨트롤러 B의 애그리게이트 1 | 컨트롤러 B의 애그리게이트 2 


| 시스템 SID1의 데이터, 로그 및 공유 볼륨 | 데이터 볼륨: SID1_DATA_mnt00001 | 공유 볼륨: SID1_shared | – | 로그 볼륨: SID1_LOG_mnt00001 


| 시스템 SID2의 데이터, 로그 및 공유 볼륨 | – | 로그 볼륨: SID2_LOG_mnt00001 | 데이터 볼륨: SID2_DATA_mnt00001 | 공유 볼륨: SID2_shared 


| 시스템 SID3의 데이터, 로그 및 공유 볼륨 | 공유 볼륨: SID3_SHARED | 데이터 볼륨: SID3_DATA_mnt00001 | 로그 볼륨: SID3_LOG_mnt00001 | – 


| 시스템 SID4의 데이터, 로그 및 공유 볼륨 | 로그 볼륨: SID4_LOG_mnt00001 | – | 공유 볼륨: SID4_shared | 데이터 볼륨: SID4_DATA_mnt00001 
|===
다음 표에는 단일 호스트 시스템의 마운트 지점 구성 예가 나와 있습니다.

|===
| LUN을 클릭합니다 | HANA 호스트의 마운트 지점 | 참고 


| SID1_DATA_mnt00001 | /HANA/data/SID1/mnt00001 | /etc/fstab 항목을 사용하여 마운트되었습니다 


| SID1_LOG_mnt00001 | /HANA/log/SID1/mnt00001 | /etc/fstab 항목을 사용하여 마운트되었습니다 


| SID1_shared | /HANA/공유/SID1 | /etc/fstab 항목을 사용하여 마운트되었습니다 
|===

NOTE: 설명된 구성에서 사용자 SID1adm 의 기본 홈 디렉토리가 저장된 '/usr/sap/sID1' 디렉토리가 로컬 디스크에 있습니다. 디스크 기반 복제를 사용하는 재해 복구 설정에서는 모든 파일 시스템이 중앙 스토리지에 있도록 '/usr/SAP/SID1' 디렉토리에 대한 'sid1_shared' 볼륨 내에 추가 LUN을 생성하는 것이 좋습니다.



== Linux LVM을 사용하여 SAP HANA 단일 호스트 시스템에 대한 볼륨 및 LUN 구성

Linux LVM을 사용하여 성능을 향상하고 LUN 크기 제한을 해결할 수 있습니다. LVM 볼륨 그룹의 서로 다른 LUN은 서로 다른 애그리게이트와 다른 컨트롤러에 저장해야 합니다. 다음 표에서는 볼륨 그룹당 2개의 LUN에 대한 예를 보여 줍니다.


NOTE: 여러 LUN에 LVM을 사용하여 SAP HANA KPI를 충족할 필요는 없습니다. 단일 LUN 설정으로 필요한 KPI를 충족합니다.

|===
| 목적 | 컨트롤러 A의 애그리게이트 1 | 컨트롤러 A의 애그리게이트 2 | 컨트롤러 B의 애그리게이트 1 | 컨트롤러 B의 애그리게이트 2 


| LVM 기반 시스템의 데이터, 로그 및 공유 볼륨 | 데이터 볼륨: SID1_DATA_mnt00001 | 공유 볼륨: SID1_shared Log2 볼륨: SID1_log2_mnt00001 | 데이터 2 볼륨: SID1_data2_mnt00001 | 로그 볼륨: SID1_LOG_mnt00001 
|===
SAP HANA 호스트에서 볼륨 그룹 및 논리적 볼륨을 생성하고 마운트해야 합니다. 다음 표에는 LVM을 사용하는 단일 호스트 시스템의 마운트 지점이 나와 있습니다.

|===
| 논리적 볼륨/LUN | SAP HANA 호스트의 마운트 지점 | 참고 


| LV:SID1_DATA_mnt0000-vol | /HANA/data/SID1/mnt00001 | /etc/fstab 항목을 사용하여 마운트되었습니다 


| LV:SID1_LOG_mnt00001-vol | /HANA/log/SID1/mnt00001 | /etc/fstab 항목을 사용하여 마운트되었습니다 


| LUN: SID1_SHARED | /HANA/공유/SID1 | /etc/fstab 항목을 사용하여 마운트되었습니다 
|===

NOTE: 설명된 구성에서 사용자 SID1adm 의 기본 홈 디렉토리가 저장된 '/usr/sap/sID1' 디렉토리가 로컬 디스크에 있습니다. 디스크 기반 복제를 사용하는 재해 복구 설정에서는 모든 파일 시스템이 중앙 스토리지에 있도록 '/usr/SAP/SID1' 디렉토리에 대한 'sid1_shared' 볼륨 내에 추가 LUN을 생성하는 것이 좋습니다.



== SAP HANA 다중 호스트 시스템을 위한 볼륨 및 LUN 구성

다음 그림에서는 4+1 다중 호스트 SAP HANA 시스템의 볼륨 구성을 보여 줍니다. 각 SAP HANA 호스트의 데이터 볼륨 및 로그 볼륨은 서로 다른 스토리지 컨트롤러에 분산됩니다. 예를 들어, 볼륨의 ID_DATA_mnt00001은 컨트롤러 A에 구성되고 볼륨의 ID_LOG_mnt00001은 컨트롤러 B에 구성됩니다 각 볼륨 내에 하나의 LUN이 구성됩니다.

'/HANA/Shared' 볼륨은 모든 HANA 호스트에서 액세스할 수 있어야 하므로 NFS를 사용하여 내보내집니다. '/HANA/공유' 파일 시스템에 대한 특정 성능 KPI가 없더라도 NetApp은 10Gb 이더넷 연결을 사용할 것을 권장합니다.


NOTE: SAP HANA 시스템에 HA 쌍의 스토리지 컨트롤러를 하나만 사용하는 경우, 데이터 및 로그 볼륨을 동일한 스토리지 컨트롤러에 저장할 수 있습니다.

image:saphana_fas_fc_image19.jpg["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]

각 SAP HANA 호스트에 대해 데이터 볼륨과 로그 볼륨이 생성됩니다. '/HANA/Shared' 볼륨은 SAP HANA 시스템의 모든 호스트에서 사용됩니다. 다음 그림에서는 4+1 다중 호스트 SAP HANA 시스템의 예제 구성을 보여 줍니다.

|===
| 목적 | 컨트롤러 A의 애그리게이트 1 | 컨트롤러 A의 애그리게이트 2 | 컨트롤러 B의 애그리게이트 1 | 컨트롤러 B의 애그리게이트 2 


| 노드 1의 데이터 및 로그 볼륨 | 데이터 볼륨: SID_DATA_mnt00001 | – | 로그 볼륨: SID_LOG_mnt00001 | – 


| 노드 2의 데이터 및 로그 볼륨 | 로그 볼륨: SID_LOG_mnt00002 | – | 데이터 볼륨: SID_DATA_mnt00002 | – 


| 노드 3의 데이터 및 로그 볼륨 | – | 데이터 볼륨: SID_DATA_mnt00003 | – | 로그 볼륨: SID_LOG_mnt00003 


| 노드 4의 데이터 및 로그 볼륨 | – | 로그 볼륨: SID_LOG_mnt00004 | – | 데이터 볼륨: SID_DATA_mnt00004 


| 모든 호스트에 대한 공유 볼륨입니다 | 공유 볼륨: SID_shared | – | – | – 
|===
다음 표에는 활성 SAP HANA 호스트 4개가 있는 다중 호스트 시스템의 구성 및 마운트 지점이 나와 있습니다.

|===
| LUN 또는 볼륨 | SAP HANA 호스트의 마운트 지점 | 참고 


| LUN: SID_DATA_mnt00001 | /HANA/data/SID/mnt00001 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_LOG_mnt00001 | /HANA/log/SID/mnt00001 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_DATA_mnt00002 | /HANA/data/SID/mnt00002 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_log_mnt00002 | /HANA/log/SID/mnt00002 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_DATA_mnt00003 | /HANA/data/SID/mnt00003 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_log_mnt00003 | /HANA/log/SID/mnt00003 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_DATA_mnt00004 | /HANA/data/SID/mnt00004 | 보관 커넥터를 사용하여 장착합니다 


| LUN: SID_log_mnt00004 | /HANA/log/SID/mnt00004 | 보관 커넥터를 사용하여 장착합니다 


| 볼륨: SID_shared | /HANA/공유/SID | NFS 및 /etc/fstab 항목을 사용하여 모든 호스트에 마운트됩니다 
|===

NOTE: 설명된 구성을 사용하면 `/usr/sap/SID` 사용자 SIDadm의 기본 홈 디렉토리가 저장되는 디렉토리가 각 HANA 호스트의 로컬 디스크에 있습니다. 디스크 기반 복제를 사용하는 재해 복구 설정에서 NetApp는 각 데이터베이스 호스트에 모든 파일 시스템이 중앙 스토리지에 있도록 파일 시스템의 볼륨에 `/usr/sap/SID` 4개의 하위 디렉토리를 추가로 생성하는 것이 좋습니다 `SID_shared`.



== Linux LVM을 사용하여 SAP HANA 다중 호스트 시스템을 위한 볼륨 및 LUN 구성

Linux LVM을 사용하여 성능을 향상하고 LUN 크기 제한을 해결할 수 있습니다. LVM 볼륨 그룹의 서로 다른 LUN은 서로 다른 애그리게이트와 다른 컨트롤러에 저장해야 합니다. 다음 표에서는 2 + 1 SAP HANA 다중 호스트 시스템에 대해 볼륨 그룹당 2개의 LUN을 보여 줍니다.


NOTE: LVM을 사용하여 여러 LUN을 결합하여 SAP HANA KPI를 충족할 필요는 없습니다. 단일 LUN 설정으로 필요한 KPI를 충족합니다.

|===
| 목적 | 컨트롤러 A의 애그리게이트 1 | 컨트롤러 A의 애그리게이트 2 | 컨트롤러 B의 애그리게이트 1 | 컨트롤러 B의 애그리게이트 2 


| 노드 1의 데이터 및 로그 볼륨 | 데이터 볼륨: SID_DATA_mnt00001 | Log2 볼륨: SID_log2_mnt00001 | 로그 볼륨: SID_LOG_mnt00001 | 데이터 2 볼륨: SID_data2_mnt00001 


| 노드 2의 데이터 및 로그 볼륨 | Log2 볼륨: SID_log2_mnt00002 | 데이터 볼륨: SID_DATA_mnt00002 | 데이터 2 볼륨: SID_data2_mnt00002 | 로그 볼륨: SID_LOG_mnt00002 


| 모든 호스트에 대한 공유 볼륨입니다 | 공유 볼륨: SID_shared | – | – | – 
|===
SAP HANA 호스트에서 볼륨 그룹 및 논리적 볼륨을 생성하고 마운트해야 합니다.

|===
| 논리 볼륨(LV) 또는 볼륨입니다 | SAP HANA 호스트의 마운트 지점 | 참고 


| LV:SID_DATA_mnt00001-vol | /HANA/data/SID/mnt00001 | 보관 커넥터를 사용하여 장착합니다 


| LV:SID_LOG_mnt00001-vol | /HANA/log/SID/mnt00001 | 보관 커넥터를 사용하여 장착합니다 


| LV:SID_DATA_mnt00002-vol | /HANA/data/SID/mnt00002 | 보관 커넥터를 사용하여 장착합니다 


| LV:SID_LOG_mnt00002-vol | /HANA/log/SID/mnt00002 | 보관 커넥터를 사용하여 장착합니다 


| 볼륨: SID_shared | /HANA/공유 | NFS 및 /etc/fstab 항목을 사용하여 모든 호스트에 마운트됩니다 
|===

NOTE: 설명된 구성에서 사용자 SIDadm의 기본 홈 디렉토리가 저장되는 '/usr/sap/sid' 디렉토리는 각 HANA 호스트의 로컬 디스크에 있습니다. 디스크 기반 복제를 사용하는 재해 복구 설정의 경우 각 데이터베이스 호스트에 중앙 스토리지에 모든 파일 시스템이 있도록 '/usr/sap/sid' 파일 시스템의 'ID_shared' 볼륨에 4개의 하위 디렉토리를 추가로 생성하는 것이 좋습니다.



== 볼륨 옵션

다음 표에 나열된 볼륨 옵션을 확인하여 모든 SVM에서 설정해야 합니다.

|===
| 조치 | ONTAP 9 


| 자동 스냅샷 복사본을 사용하지 않도록 설정합니다 | vol modify –vserver <vserver-name> -volume <volname> -snapshot-policy none 


| 스냅샷 디렉토리 표시를 해제합니다 | vol modify -vserver <vserver-name> -volume <volname> -snapdir -access false 
|===


== LUN 생성, 볼륨 및 LUN을 이니시에이터 그룹에 매핑

NetApp ONTAP System Manager를 사용하여 스토리지 볼륨과 LUN을 생성하고 이를 서버의 igroup 및 ONTAP CLI에 매핑할 수 있습니다. 이 가이드에서는 CLI 사용에 대해 설명합니다.



=== CLI를 사용하여 LUN, 볼륨 생성 및 LUN을 igroup에 매핑

이 섹션에서는 LVM을 사용하는 SID FC5와 LVM 볼륨 그룹당 2개의 LUN을 사용하는 2+1 SAP HANA 다중 호스트 시스템에 대해 ONTAP 9과 함께 명령줄을 사용하는 구성의 예를 보여 줍니다.

. 필요한 볼륨을 모두 생성합니다.
+
....
vol create -volume FC5_data_mnt00001 -aggregate aggr1_1 -size 1200g  -snapshot-policy none -foreground true -encrypt false  -space-guarantee none
vol create -volume FC5_log_mnt00002  -aggregate aggr2_1 -size 280g  -snapshot-policy none -foreground true -encrypt false  -space-guarantee none
vol create -volume FC5_log_mnt00001  -aggregate aggr1_2 -size 280g -snapshot-policy none -foreground true -encrypt false -space-guarantee none
vol create -volume FC5_data_mnt00002  -aggregate aggr2_2 -size 1200g -snapshot-policy none -foreground true -encrypt false -space-guarantee none
vol create -volume FC5_data2_mnt00001 -aggregate aggr1_2 -size 1200g -snapshot-policy none -foreground true -encrypt false -space-guarantee none
vol create -volume FC5_log2_mnt00002  -aggregate aggr2_2 -size 280g -snapshot-policy none -foreground true -encrypt false -space-guarantee none
vol create -volume FC5_log2_mnt00001  -aggregate aggr1_1 -size 280g -snapshot-policy none -foreground true -encrypt false  -space-guarantee none
vol create -volume FC5_data2_mnt00002  -aggregate aggr2_1 -size 1200g -snapshot-policy none -foreground true -encrypt false -space-guarantee none
vol create -volume FC5_shared -aggregate aggr1_1 -size 512g -state online -policy default -snapshot-policy none -junction-path /FC5_shared -encrypt false  -space-guarantee none
....
. 모든 LUN을 생성합니다.
+
....
lun create -path  /vol/FC5_data_mnt00001/FC5_data_mnt00001   -size 1t -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_data2_mnt00001/FC5_data2_mnt00001 -size 1t -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_data_mnt00002/FC5_data_mnt00002 -size 1t -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_data2_mnt00002/FC5_data2_mnt00002 -size 1t -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_log_mnt00001/FC5_log_mnt00001 -size 260g -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_log2_mnt00001/FC5_log2_mnt00001 -size 260g -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_log_mnt00002/FC5_log_mnt00002 -size 260g -ostype linux -space-reserve disabled -space-allocation disabled -class regular
lun create -path /vol/FC5_log2_mnt00002/FC5_log2_mnt00002 -size 260g -ostype linux -space-reserve disabled -space-allocation disabled -class regular
....
. 시스템 FC5에 속하는 모든 서버에 대한 igroup을 생성합니다.
+
....
lun igroup create -igroup HANA-FC5 -protocol fcp -ostype linux -initiator 10000090fadcc5fa,10000090fadcc5fb, 10000090fadcc5c1,10000090fadcc5c2,  10000090fadcc5c3,10000090fadcc5c4 -vserver hana
....
. 모든 LUN을 생성된 igroup에 매핑합니다.
+
....
lun map -path  /vol/FC5_data_mnt00001/FC5_data_mnt00001    -igroup HANA-FC5
lun map -path /vol/FC5_data2_mnt00001/FC5_data2_mnt00001  -igroup HANA-FC5
lun map -path /vol/FC5_data_mnt00002/FC5_data_mnt00002  -igroup HANA-FC5
lun map -path /vol/FC5_data2_mnt00002/FC5_data2_mnt00002  -igroup HANA-FC5
lun map -path /vol/FC5_log_mnt00001/FC5_log_mnt00001  -igroup HANA-FC5
lun map -path /vol/FC5_log2_mnt00001/FC5_log2_mnt00001  -igroup HANA-FC5
lun map -path /vol/FC5_log_mnt00002/FC5_log_mnt00002  -igroup HANA-FC5
lun map -path /vol/FC5_log2_mnt00002/FC5_log2_mnt00002  -igroup HANA-FC5
....

